{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skopt                           import forest_minimize\n",
    "from lightgbm                        import LGBMClassifier\n",
    "from scipy.sparse                    import hstack, csr_matrix\n",
    "from sklearn.metrics                 import roc_auc_score, average_precision_score\n",
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.preprocessing           import MaxAbsScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = pd.read_feather('../Data/FeatherData/dfAllDataLabeled.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = dfRaw.sort_values('UploadDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures = pd.DataFrame(index=dfRaw.index)\n",
    "dfFeatures['ViewCount'] = dfRaw['ViewCount']\n",
    "dfFeatures['DaysSincePublication'] = dfRaw['DaysSincePublication']\n",
    "dfFeatures['WatchList'] = dfRaw['WatchList']\n",
    "dfFeatures['ViewsPerDay'] = dfFeatures['ViewCount'] / dfFeatures['DaysSincePublication']\n",
    "dfFeatures = dfFeatures.drop('DaysSincePublication', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split DataFrame into Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-11-27 00:00:00')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfRaw['UploadDate'].iloc[int(round(dfRaw.shape[0]/2,0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateSplit = '2019-11-27'\n",
    "\n",
    "maskTrain = (dfRaw['UploadDate'] < dateSplit)\n",
    "\n",
    "maskVal = (dfRaw['UploadDate'] >= dateSplit)\n",
    "\n",
    "Xtrain, Xval = dfFeatures[maskTrain].drop('WatchList', axis=1) , dfFeatures[maskVal].drop('WatchList', axis=1)\n",
    "ytrain, yval = dfFeatures[maskTrain]['WatchList'], dfFeatures[maskVal]['WatchList']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((885, 2), (888, 2), (885,), (888,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xval.shape, ytrain.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleTrain = dfRaw[maskTrain]['Title']\n",
    "titleVal = dfRaw[maskVal]['Title']\n",
    "\n",
    "titleVec = TfidfVectorizer(min_df=4, ngram_range=(1,2))\n",
    "titleBowTrain = titleVec.fit_transform(titleTrain)\n",
    "titleBowVal = titleVec.transform(titleVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885, 495)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleBowTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<885x495 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8627 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleBowTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainWTitle = hstack([Xtrain, titleBowTrain])\n",
    "XvalWTitle = hstack([Xval, titleBowVal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((885, 497), (888, 497))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainWTitle.shape, XvalWTitle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', min_samples_leaf=2,\n",
       "                       n_estimators=1500, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1500, random_state=0, min_samples_leaf=2, class_weight='balanced', n_jobs=-1)\n",
    "rf.fit(XtrainWTitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pRf = rf.predict_proba(XvalWTitle)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap: 0.425697264360267, auc: 0.7845256438476778\n"
     ]
    }
   ],
   "source": [
    "print(f'ap: {average_precision_score(yval, pRf)}, auc: {roc_auc_score(yval, pRf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap: 0.3521564476834772, auc: 0.7758089368258859 | min_samples_leaf=1\n",
    "# ap: 0.3843011851670597, auc: 0.7815540391811577 | min_samples_leaf=2\n",
    "# ap: 0.38551950447476385, auc: 0.7831168831168831 | n_estimators=1500\n",
    "# ap: 0.40864867634952645, auc: 0.7861765353290777 | min_df=3\n",
    "# ap: 0.4138684826920506, auc: 0.784668721109399 | ngram_range = (1,2)\n",
    "# ap: 0.425697264360267, auc: 0.7845256438476778 | min_df=4 & ngram_range = (1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', random_state=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLGBM = LGBMClassifier(random_state=0, class_weight='balanced', n_jobs=-1)\n",
    "modelLGBM.fit(XtrainWTitle, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pLGBM = modelLGBM.predict_proba(XvalWTitle)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap: 0.3613860826479734, auc: 0.7497248514197665\n"
     ]
    }
   ],
   "source": [
    "print(f'ap: {average_precision_score(yval,pLGBM)}, auc: {roc_auc_score(yval, pLGBM)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "[0.009944912110647982, 5, 1, 0.4677107511929402, 0.49263223036174764, 272, 3, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7713295179396874\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 1.7412\n",
      "Function value obtained: -0.3746\n",
      "Current minimum: -0.3746\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "[0.053887464791860025, 1, 15, 0.7437489153990157, 0.8675167974293533, 549, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7705040721989873\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.6712\n",
      "Function value obtained: -0.3512\n",
      "Current minimum: -0.3746\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "[0.004151454520895999, 6, 20, 0.8682075103820793, 0.9491436163200662, 411, 4, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7800187101034559\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1.1207\n",
      "Function value obtained: -0.3856\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "[0.0014099928811969545, 9, 9, 0.6502182010234373, 0.6866210554187129, 828, 5, 2]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7812788906009246\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 3.2514\n",
      "Function value obtained: -0.3764\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "[0.08530558241838007, 8, 19, 0.2137736299768322, 0.1313765544201984, 961, 4, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6443869689632402\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 1.4358\n",
      "Function value obtained: -0.2752\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "[0.003567949451535685, 10, 19, 0.7232951768944309, 0.7298538828427115, 939, 4, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7767774598283074\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 3.6843\n",
      "Function value obtained: -0.3694\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "[0.014828577273549474, 7, 1, 0.18428087097824575, 0.3261556557915816, 274, 1, 2]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7427030596522122\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 5.0720\n",
      "Function value obtained: -0.2977\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "[0.0015212976972079912, 3, 12, 0.44234694306528044, 0.399351303640462, 272, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7745597622716266\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 1.2124\n",
      "Function value obtained: -0.3856\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "[0.01946212855369041, 9, 18, 0.5235636153223084, 0.6728679300083596, 747, 4, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7432643627558881\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 2.0807\n",
      "Function value obtained: -0.3272\n",
      "Current minimum: -0.3856\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "[0.0012116790683302117, 3, 2, 0.06616307483844217, 0.23025600705315752, 677, 2, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7522452124147039\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 4.6374\n",
      "Function value obtained: -0.3906\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "[0.0053139776214487944, 6, 9, 0.14251441334450304, 0.8175761405215897, 297, 1, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7482335461149019\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 1.4502\n",
      "Function value obtained: -0.3523\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 12 started. Evaluating function at random point.\n",
      "[0.0068572961982704935, 10, 5, 0.2390386584472456, 0.49053406102209746, 176, 2, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7520581113801454\n",
      "Iteration No: 12 ended. Evaluation done at random point.\n",
      "Time taken: 1.7793\n",
      "Function value obtained: -0.3451\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 13 started. Evaluating function at random point.\n",
      "[0.00781968225875022, 3, 4, 0.7078936710077383, 0.31818755505678337, 275, 4, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7733711204050187\n",
      "Iteration No: 13 ended. Evaluation done at random point.\n",
      "Time taken: 0.9306\n",
      "Function value obtained: -0.3810\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 14 started. Evaluating function at random point.\n",
      "[0.017293945600511968, 2, 15, 0.9007557574888567, 0.41026441194439994, 316, 5, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7704435395113362\n",
      "Iteration No: 14 ended. Evaluation done at random point.\n",
      "Time taken: 0.4794\n",
      "Function value obtained: -0.3775\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 15 started. Evaluating function at random point.\n",
      "[0.012250750764764855, 8, 6, 0.5976582413192033, 0.2474882432951916, 516, 4, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7757208892802112\n",
      "Iteration No: 15 ended. Evaluation done at random point.\n",
      "Time taken: 2.0885\n",
      "Function value obtained: -0.3727\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 16 started. Evaluating function at random point.\n",
      "[0.018353598126553926, 4, 3, 0.47305622526323254, 0.1404164811277527, 133, 4, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7598558221439577\n",
      "Iteration No: 16 ended. Evaluation done at random point.\n",
      "Time taken: 0.7065\n",
      "Function value obtained: -0.3438\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 17 started. Evaluating function at random point.\n",
      "[0.0010383234748454694, 9, 19, 0.9256771571832196, 0.9321438677645206, 312, 4, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7719018269865727\n",
      "Iteration No: 17 ended. Evaluation done at random point.\n",
      "Time taken: 1.1787\n",
      "Function value obtained: -0.3860\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 18 started. Evaluating function at random point.\n",
      "[0.004955229758078229, 5, 5, 0.06939551310802591, 0.4193273080472823, 725, 4, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7094541052168171\n",
      "Iteration No: 18 ended. Evaluation done at random point.\n",
      "Time taken: 1.7095\n",
      "Function value obtained: -0.3583\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 19 started. Evaluating function at random point.\n",
      "[0.0699516121742407, 9, 10, 0.6477856515609233, 0.8594430701440198, 616, 1, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7317631521021353\n",
      "Iteration No: 19 ended. Evaluation done at random point.\n",
      "Time taken: 2.3030\n",
      "Function value obtained: -0.3107\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 20 started. Evaluating function at random point.\n",
      "[0.0014752743467850462, 5, 4, 0.9747950537021096, 0.982207187458162, 909, 2, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7506713625357693\n",
      "Iteration No: 20 ended. Evaluation done at random point.\n",
      "Time taken: 3.4184\n",
      "Function value obtained: -0.3164\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "[0.0015516166698099135, 7, 18, 0.18749963073364717, 0.6256245155101512, 433, 5, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7092780101254677\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.3569\n",
      "Function value obtained: -0.3465\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "[0.011584587991181958, 10, 20, 0.8562246117181807, 0.2577370290811061, 174, 5, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7819282412502753\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4040\n",
      "Function value obtained: -0.3663\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "[0.035230817425761216, 1, 12, 0.9868337005698143, 0.3088673129812297, 284, 5, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7672903367818622\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.0907\n",
      "Function value obtained: -0.3503\n",
      "Current minimum: -0.3906\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "[0.0011719768867422022, 3, 20, 0.298182268755055, 0.05728042749221888, 960, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7698217037200088\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.2376\n",
      "Function value obtained: -0.4006\n",
      "Current minimum: -0.4006\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "[0.001097694498059047, 3, 15, 0.10072230522875493, 0.19561260395390823, 660, 1, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6827151661897424\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0522\n",
      "Function value obtained: -0.3194\n",
      "Current minimum: -0.4006\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "[0.0019574441931429227, 2, 7, 0.11075388234583461, 0.11688508423102786, 956, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7842504952674443\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.2453\n",
      "Function value obtained: -0.3978\n",
      "Current minimum: -0.4006\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "[0.001477438108754858, 3, 10, 0.16137221087324535, 0.19593296243176872, 966, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7806845696676206\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.9938\n",
      "Function value obtained: -0.4227\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "[0.0015868932745085498, 3, 8, 0.204286420902765, 0.08964715068233683, 866, 2, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7685780321373541\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.3672\n",
      "Function value obtained: -0.3751\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "[0.002819417576260184, 4, 16, 0.3642172028835449, 0.1738753371025086, 952, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7594981289896545\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.9501\n",
      "Function value obtained: -0.3703\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "[0.001374801274295025, 10, 4, 0.22905013144293812, 0.19954136222716767, 922, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7749284613691394\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1483\n",
      "Function value obtained: -0.3844\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "[0.00805939219383168, 3, 4, 0.2585010408596497, 0.2361303028827081, 954, 5, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7752036099493728\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.3388\n",
      "Function value obtained: -0.3665\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "[0.0010183487120473543, 8, 13, 0.11729475778496079, 0.16982745731767535, 963, 3, 1]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.716486902927581\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1194\n",
      "Function value obtained: -0.3257\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "[0.001577181657847308, 2, 10, 0.1348634089185734, 0.22318195055510603, 946, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7791822584195466\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.7425\n",
      "Function value obtained: -0.4044\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "[0.001997959295305105, 1, 12, 0.16895795872125735, 0.28907915711557064, 968, 2, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7693704600484262\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.4649\n",
      "Function value obtained: -0.3994\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "[0.0016568223725595202, 2, 18, 0.06325719448075796, 0.23130074054595834, 952, 1, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6324069997798811\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.9485\n",
      "Function value obtained: -0.2224\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "[0.0013168146017606165, 2, 16, 0.15254654100702367, 0.21234122328653537, 637, 3, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7271241470394012\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.7471\n",
      "Function value obtained: -0.3672\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "[0.0012714470466333341, 3, 16, 0.5518641370199713, 0.3882381233582498, 957, 2, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7705040721989874\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1429\n",
      "Function value obtained: -0.3786\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "[0.0011942155595447465, 3, 19, 0.19685171244686472, 0.29634494051797283, 985, 2, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7273167510455646\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3882\n",
      "Function value obtained: -0.3866\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "[0.0014261833150572443, 1, 14, 0.051489577854192975, 0.23842895372573436, 916, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6325390710983931\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.8651\n",
      "Function value obtained: -0.2358\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "[0.002195584878408933, 5, 18, 0.09059678607807446, 0.19161013279025618, 929, 4, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6581884217477438\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0512\n",
      "Function value obtained: -0.2529\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "[0.00131188971268959, 2, 11, 0.06018214530898241, 0.5364894065882069, 872, 3, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6874202069117323\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.3765\n",
      "Function value obtained: -0.3067\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "[0.0037789367273395476, 2, 2, 0.09808389514933721, 0.2939254745043286, 960, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7786044464010565\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.1840\n",
      "Function value obtained: -0.4098\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "[0.0017466167565249224, 4, 10, 0.08757746318405793, 0.15001217982045545, 997, 4, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7264142637023994\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.7660\n",
      "Function value obtained: -0.3590\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "[0.0014717237143463753, 2, 10, 0.06831161067412415, 0.178183152144896, 677, 3, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7127503852080124\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.0922\n",
      "Function value obtained: -0.3816\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "[0.0013606898270954162, 2, 19, 0.13227255766014812, 0.05407329697655785, 962, 3, 4]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7051893022232005\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1079\n",
      "Function value obtained: -0.3772\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "[0.0031304259295205435, 2, 7, 0.0613082773547023, 0.29621772924408535, 941, 3, 2]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7412942989214175\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.5996\n",
      "Function value obtained: -0.4118\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "[0.0022529874330958826, 2, 20, 0.052954800051254095, 0.06683324151779446, 735, 2, 3]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.6232665639445301\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 1.4523\n",
      "Function value obtained: -0.2232\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "[0.001644518593035039, 2, 20, 0.25663963277469237, 0.3828209115492502, 926, 2, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7686220559101915\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.2728\n",
      "Function value obtained: -0.3931\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "[0.004717276758544176, 2, 12, 0.06125653652565545, 0.3403869493425924, 869, 2, 5]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.674570768214836\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 2.1811\n",
      "Function value obtained: -0.2788\n",
      "Current minimum: -0.4227\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "[0.005808607122131676, 2, 1, 0.09836941961022068, 0.22240024381622447, 931, 2, 2]\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "0.7721329517939687\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.9518\n",
      "Function value obtained: -0.3749\n",
      "Current minimum: -0.4227\n"
     ]
    }
   ],
   "source": [
    "def tuneLGBM(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    titleVec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "    titleBowTrain = titleVec.fit_transform(titleTrain)\n",
    "    titleBowVal = titleVec.transform(titleVal)\n",
    "    \n",
    "    XtrainWTitle = hstack([Xtrain, titleBowTrain])\n",
    "    XvalWTitle = hstack([Xval, titleBowVal])\n",
    "    \n",
    "    model = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                           min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                           bagging_freq=1, n_estimators=n_estimators, random_state=0, class_weight='balanced', n_jobs=-1)\n",
    "    \n",
    "    model.fit(XtrainWTitle, ytrain)\n",
    "    \n",
    "    p = model.predict_proba(XvalWTitle)[:,1]\n",
    "    \n",
    "    print(roc_auc_score(yval, p))\n",
    "    \n",
    "    return -average_precision_score(yval,p)\n",
    "\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), #lr\n",
    "        (1, 10), #max_depth\n",
    "        (1, 20), #min_child_samples\n",
    "        (0.05, 1.0), #subsample\n",
    "        (0.05, 1.0), #colsample_bytree\n",
    "        (100, 1000), #n_estimetors\n",
    "        (1, 5), #min_df\n",
    "        (1, 5)] #ngram_range\n",
    "\n",
    "\n",
    "\n",
    "result = forest_minimize(tuneLGBM, space, random_state=160745, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.001477438108754858,\n",
       " 3,\n",
       " 10,\n",
       " 0.16137221087324535,\n",
       " 0.19593296243176872,\n",
       " 966,\n",
       " 3,\n",
       " 5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier\n",
    "\n",
    "[0.001477438108754858, 3, 10, 0.16137221087324535, 0.19593296243176872, 966, 3, 5]\n",
    "ap: 0.4227, auc: 0.7806845696676206"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model With Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "ap: 0.41114784456628284, auc: 0.7786154523442659\n"
     ]
    }
   ],
   "source": [
    "params = [0.001477438108754858, #lr\n",
    " 3, #max_depth\n",
    " 10, #min_child_samples\n",
    " 0.16137221087324535, #subsample\n",
    " 0.19593296243176872, #colsample_bytree\n",
    " 966, #n_estimetors\n",
    " 2,  #min_df\n",
    " 5] #ngram_range\n",
    "\n",
    "\n",
    "\n",
    "lr = params[0]\n",
    "max_depth = params[1]\n",
    "min_child_samples = params[2]\n",
    "subsample = params[3]\n",
    "colsample_bytree = params[4]\n",
    "n_estimators = params[5]\n",
    "min_df = params[6]\n",
    "ngram_range = (1, params[7])\n",
    "\n",
    "titleVec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range)\n",
    "titleBowTrain = titleVec.fit_transform(titleTrain)\n",
    "titleBowVal = titleVec.transform(titleVal)\n",
    "\n",
    "XtrainWTitle = hstack([Xtrain, titleBowTrain])\n",
    "XvalWTitle = hstack([Xval, titleBowVal])\n",
    "\n",
    "model = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth,\n",
    "                       min_child_samples=min_child_samples, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                       bagging_freq=1, n_estimators=n_estimators, random_state=0, class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "model.fit(XtrainWTitle, ytrain)\n",
    "\n",
    "pLgbm = model.predict_proba(XvalWTitle)[:,1]\n",
    "\n",
    "\n",
    "print(f'ap: {average_precision_score(yval,pLgbm)}, auc: {roc_auc_score(yval, pLgbm)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainWTitle2 = csr_matrix(XtrainWTitle.copy())\n",
    "XvalWTitle2 = csr_matrix(XvalWTitle.copy())\n",
    "\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "XtrainWTitle2 = scaler.fit_transform(XtrainWTitle2)\n",
    "XvalWTitle2 = scaler.transform(XvalWTitle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(888, 2454)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XvalWTitle2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, n_jobs=-1, random_state=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.01, n_jobs=-1, random_state=0)\n",
    "model.fit(XtrainWTitle2, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pLr = model.predict_proba(XvalWTitle2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap: 0.3809915480394665, auc: 0.7685009905348889\n"
     ]
    }
   ],
   "source": [
    "print(f'ap: {average_precision_score(yval, pLr)}, auc: {roc_auc_score(yval, pLr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ap: 0.3986324868099709, auc: 0.7804974686330618"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_df > 3\n",
    "- LGBM | ap: 0.42266615524449913, auc: 0.7806845696676206\n",
    "- LR   | ap: 0.3986324868099709, auc: 0.7804974686330618\n",
    "\n",
    "#### min_df > 2\n",
    "- LGBM | ap: 0.41114784456628284, auc: 0.7786154523442659\n",
    "- LR   | ap: 0.3809915480394665, auc: 0.7685009905348889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.792928</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR      LGBM\n",
       "LR    1.000000  0.792928\n",
       "LGBM  0.792928  1.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'LR': pLr, 'LGBM': pLgbm}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap: 0.4242863619606607, auc: 0.7871010345586616\n"
     ]
    }
   ],
   "source": [
    "p = (0.30*pLgbm + 0.70*pLr)\n",
    "print(f'ap: {average_precision_score(yval,p)}, auc: {roc_auc_score(yval, p)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
